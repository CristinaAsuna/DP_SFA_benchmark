{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8db91bf",
   "metadata": {},
   "source": [
    "总体"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c35804e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy.stats import halfnorm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "import seaborn as sns\n",
    "\n",
    "# Stochastic Frontier Model类\n",
    "class StochasticFrontierModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.beta = nn.Parameter(torch.tensor(num_features * [1.0], dtype=torch.float32))\n",
    "        self.log_sigma2 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.log_lambda0 = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def predict(self, x):\n",
    "        # 使用 torch.matmul 执行矩阵乘法\n",
    "        predictions = torch.matmul(x, self.beta)\n",
    "        return predictions\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        sigma2 = torch.exp(self.log_sigma2)\n",
    "        lambda0 = torch.exp(self.log_lambda0)\n",
    "        sigma = torch.sqrt(sigma2)\n",
    "        epsilon = y - torch.sum(x * self.beta, dim=1)\n",
    "\n",
    "        term1 = x.shape[0] * self.log_sigma2 / 2\n",
    "        term2 = -torch.sum(torch.log(torch.distributions.normal.Normal(0, 1).cdf(-epsilon * lambda0 / sigma) + 1e-10))\n",
    "        term3 = torch.sum(epsilon**2) / (2 * sigma2)\n",
    "\n",
    "        return (term1 + term2 + term3) / x.shape[0]\n",
    "\n",
    "# 数据生成模块\n",
    "def generate_data(num_features, sigma_u, sigma_v, N, save_path='true_parameters.csv'):\n",
    "    \"\"\"\n",
    "    生成数据，并保存真实的 beta、lambda、sigma_sq 等参数到 CSV 文件。\n",
    "    :param num_features: 特征数量\n",
    "    :param sigma_u: 非负噪声的标准差\n",
    "    :param sigma_v: 随机噪声的标准差\n",
    "    :param N: 样本数量\n",
    "    :param save_path: 保存真实参数的 CSV 文件路径\n",
    "    :return: x, y, true_beta\n",
    "    \"\"\"\n",
    "    # 生成稀疏的 beta 向量（num_features 维，只有 6 个非零系数，取值为 1 或 -1）\n",
    "    beta = np.zeros(num_features)\n",
    "    non_zero_indices = np.random.choice(num_features, 6, replace=False)  # 随机选择 6 个非零位置\n",
    "    beta[non_zero_indices] = np.random.choice([-1, 1], 6)  # 非零系数为 1 或 -1\n",
    "\n",
    "    # 生成特征数据 x\n",
    "    x = np.random.normal(0, 1, (N, num_features))  # num_features 维特征，服从标准正态分布\n",
    "\n",
    "    # 生成噪声 v 和 u\n",
    "    v = np.random.normal(0, sigma_v, N)  # 随机噪声 v\n",
    "    u = stats.halfnorm.rvs(loc=0, scale=sigma_u, size=N)  # 非负噪声 u\n",
    "\n",
    "    # 生成目标变量 y\n",
    "    y = x.dot(beta) + v - u\n",
    "\n",
    "    # 保存真实参数到 CSV 文件\n",
    "    true_params = {\n",
    "        'beta': beta,\n",
    "        'lambda': sigma_u / sigma_v,  # lambda = sigma_u / sigma_v\n",
    "        'sigma_sq': sigma_u**2 + sigma_v**2  # sigma^2 = sigma_u^2 + sigma_v^2\n",
    "    }\n",
    "    pd.DataFrame(true_params).to_csv(save_path, index=False)\n",
    "\n",
    "    # 保存生成的数据\n",
    "    data = np.hstack([x, y.reshape(-1, 1)])\n",
    "    pd.DataFrame(data, columns=[f'x{i}' for i in range(num_features)] + ['y']).to_csv('data.csv', index=False)\n",
    "\n",
    "    return x, y, beta\n",
    "\n",
    "# MLE 变量选择模块\n",
    "def stochastic_frontier_mle_lasso_bic(x, y, r_range=np.logspace(-2, 4, 3), threshold=1e-3, max_iter=2):\n",
    "    \"\"\"\n",
    "    使用自适应 Lasso 惩罚的随机前沿模型进行变量选择和参数估计。\n",
    "    :param x: 特征矩阵\n",
    "    :param y: 目标变量\n",
    "    :param r_range: Lasso 惩罚参数的范围\n",
    "    :param threshold: 系数阈值，小于该值的系数设为 0\n",
    "    :param max_iter: 最大迭代次数\n",
    "    :return: 估计的 beta, lambda, sigma^2, MSE, BIC, 最优 r\n",
    "    \"\"\"\n",
    "    x_df = pd.DataFrame(x)\n",
    "    y_series = pd.Series(y)\n",
    "\n",
    "    def calculate_bic(r, x_df, y_series):\n",
    "        # 第一次 Lasso 估计\n",
    "        lasso = Lasso(alpha=r)\n",
    "        lasso.fit(x_df, y_series)\n",
    "        beta_init = lasso.coef_\n",
    "\n",
    "        # 计算自适应 Lasso 权重\n",
    "        w = np.zeros_like(beta_init)\n",
    "        for j in range(len(beta_init)):\n",
    "            if np.abs(beta_init[j]) > threshold:\n",
    "                w[j] = 1 / np.abs(beta_init[j])\n",
    "            else:\n",
    "                w[j] = 0\n",
    "\n",
    "        def logLikFun(param):\n",
    "            parlab = param[:-2]\n",
    "            parsigmaSq = param[-2]\n",
    "            parlambda = param[-1]\n",
    "            epsilon = y_series - np.dot(x_df, parlab)\n",
    "            penalty = r * np.sum(w * np.abs(parlab))\n",
    "            return -np.sum(0.5 * np.log(parsigmaSq) + 0.5 / parsigmaSq * epsilon**2 -\n",
    "                           norm.logcdf(-epsilon * parlambda / np.sqrt(parsigmaSq))) + penalty\n",
    "\n",
    "        # 使用最小二乘法获取初始参数\n",
    "        ols = sm.OLS(y_series, x_df).fit()\n",
    "        init_params = np.append(ols.params.values, [0.5, sum(ols.resid**2) / (len(y_series) - len(ols.params))])\n",
    "\n",
    "        # 极大似然估计\n",
    "        result = minimize(lambda params: -logLikFun(params), init_params, method='Nelder-Mead')\n",
    "\n",
    "        # 提取估计的参数\n",
    "        beta = result.x[:-2]\n",
    "        sigma_sq = result.x[-2]\n",
    "        lambda_ = result.x[-1]\n",
    "\n",
    "        # 后处理：将绝对值小于阈值的系数设为 0\n",
    "        beta[np.abs(beta) < threshold] = 0\n",
    "\n",
    "        # 计算对数似然值\n",
    "        log_lik = -logLikFun(result.x)\n",
    "\n",
    "        # 计算 BIC\n",
    "        n = len(y_series)\n",
    "        k = np.sum(beta != 0) + 2\n",
    "        bic = -2 * log_lik + k * np.log(n)\n",
    "\n",
    "        return bic, beta, lambda_, sigma_sq\n",
    "\n",
    "    # 初始化\n",
    "    best_bic = np.inf\n",
    "    best_r = None\n",
    "    best_beta = None\n",
    "    best_lambda = None\n",
    "    best_sigma_sq = None\n",
    "    best_features = None\n",
    "\n",
    "    # 遍历 r_range，选择使 BIC 最小的 r\n",
    "    for r in r_range:\n",
    "        # 初始估计\n",
    "        bic, beta, lambda_, sigma_sq = calculate_bic(r, x_df, y_series)\n",
    "\n",
    "        # 迭代筛选和重新估计\n",
    "        for _ in range(max_iter):\n",
    "            # 筛选出非零特征\n",
    "            selected_features = np.abs(beta) >= threshold\n",
    "            if not np.any(selected_features):\n",
    "                break\n",
    "\n",
    "            # 确保 selected_features 的长度与 x_df 的列数一致\n",
    "            if len(selected_features) != x_df.shape[1]:\n",
    "                selected_features = np.append(selected_features, [False] * (x_df.shape[1] - len(selected_features)))\n",
    "\n",
    "            # 使用筛选后的特征重新估计\n",
    "            x_filtered = x_df.loc[:, selected_features]\n",
    "            bic_new, beta_new, lambda_new, sigma_sq_new = calculate_bic(r, x_filtered, y_series)\n",
    "\n",
    "            # 如果 BIC 没有改善，停止迭代\n",
    "            if bic_new >= bic:\n",
    "                break\n",
    "\n",
    "            # 更新结果\n",
    "            bic, beta, lambda_, sigma_sq = bic_new, beta_new, lambda_new, sigma_sq_new\n",
    "\n",
    "        # 记录最优结果\n",
    "        if bic < best_bic:\n",
    "            best_bic = bic\n",
    "            best_r = r\n",
    "            best_beta = beta\n",
    "            best_lambda = lambda_\n",
    "            best_sigma_sq = sigma_sq\n",
    "            best_features = selected_features\n",
    "\n",
    "    # 确保 best_features 的长度与 best_beta 的长度一致\n",
    "    if len(best_features) != len(best_beta):\n",
    "        best_features = np.abs(best_beta) >= threshold\n",
    "\n",
    "    # 计算 MSE\n",
    "    epsilon = y_series - np.dot(x_df.loc[:, best_features], best_beta[best_features])\n",
    "    mse = np.mean(epsilon**2)\n",
    "\n",
    "    return best_beta, best_lambda, best_sigma_sq, mse, best_bic, best_r\n",
    "\n",
    "# 非私有和私有方法模块\n",
    "def train_model_without_private(x, y, num_features, num_iters=3000, constraint=100, minibatch_size=50, threshold=1e-3):\n",
    "    \"\"\"\n",
    "    训练非私有模型。\n",
    "    \"\"\"\n",
    "    x, mean, std = standardize_data(x)\n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    model = StochasticFrontierModel(num_features=num_features)\n",
    "    losses = []\n",
    "    gradients = []\n",
    "    parameters = []\n",
    "\n",
    "    for i in tqdm(range(1, num_iters + 1), desc=\"Training without privacy\"):\n",
    "        minibatch_indices = np.random.choice(x.shape[0], minibatch_size, replace=True)\n",
    "        minibatch_x = x[minibatch_indices]\n",
    "        minibatch_y = y[minibatch_indices]\n",
    "        loss = model(minibatch_x, minibatch_y)\n",
    "        loss.backward()\n",
    "        gradient = torch.cat([p.grad.flatten() for p in model.parameters()]).detach().numpy()\n",
    "        pos_alphas = compute_alpha(constraint, gradient, model)\n",
    "        neg_alphas = compute_alpha(-constraint, gradient, model)\n",
    "        alphas = pos_alphas + neg_alphas\n",
    "        min_alpha, size, corner_num = min(alphas, key=lambda x: x[0])\n",
    "        corner = np.zeros(sum(p.numel() for p in model.parameters()))\n",
    "        corner[corner_num] = size\n",
    "        mu = 2 / (i + 2)\n",
    "        with torch.no_grad():\n",
    "            index = 0\n",
    "            for p in model.parameters():\n",
    "                numel = p.numel()\n",
    "                p_flat = p.view(-1)\n",
    "                p_flat.copy_((1 - mu) * p_flat + mu * torch.tensor(corner[index:index+numel], dtype=torch.float32))\n",
    "                index += numel\n",
    "        losses.append(loss.item())\n",
    "        gradients.append(np.linalg.norm(gradient))  # 记录梯度的范数\n",
    "        parameters.append(model.state_dict().copy())\n",
    "        model.zero_grad()\n",
    "\n",
    "    min_loss_index = np.argmin(losses)\n",
    "    model.load_state_dict(parameters[min_loss_index])\n",
    "\n",
    "    # 后处理：将绝对值小于阈值的系数设为0\n",
    "    with torch.no_grad():\n",
    "        model.beta[torch.abs(model.beta) < threshold] = 0\n",
    "\n",
    "    return model, mean, std, losses[-1], calculate_mse(model, x, y)\n",
    "\n",
    "def train_model_private(x, y, num_features, num_iters=3000, constraint=100, minibatch_size=50, lipschitz=1, epsilon=0.1, delta=1e-5, threshold=1e-3):\n",
    "    \"\"\"\n",
    "    训练私有模型。\n",
    "    \"\"\"\n",
    "    x, mean, std = standardize_data(x)\n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    model = StochasticFrontierModel(num_features=num_features)\n",
    "    n = x.shape[0]\n",
    "    m = sum(p.numel() for p in model.parameters())\n",
    "    losses = []\n",
    "    gradients = []\n",
    "    parameters = []\n",
    "    noise_para = lipschitz * constraint * math.sqrt(8 * num_iters * math.log(1 / delta)) / (n * epsilon)\n",
    "\n",
    "    for i in tqdm(range(1, num_iters + 1), desc=\"Training with privacy\"):\n",
    "        minibatch_indices = np.random.choice(x.shape[0], minibatch_size, replace=True)\n",
    "        minibatch_x = x[minibatch_indices]\n",
    "        minibatch_y = y[minibatch_indices]\n",
    "        loss = model(minibatch_x, minibatch_y)\n",
    "        loss.backward()\n",
    "        gradient = torch.cat([p.grad.flatten() for p in model.parameters()]).detach().numpy()\n",
    "        pos_alphas = compute_alpha_private(constraint, gradient, model, noise_para)\n",
    "        neg_alphas = compute_alpha_private(-constraint, gradient, model, noise_para)\n",
    "        alphas = pos_alphas + neg_alphas\n",
    "        min_alpha, size, corner_num = min(alphas, key=lambda x: x[0])\n",
    "        corner = np.zeros(m)\n",
    "        corner[corner_num] = size\n",
    "        mu = 2 / (i + 2)\n",
    "        with torch.no_grad():\n",
    "            index = 0\n",
    "            for p in model.parameters():\n",
    "                numel = p.numel()\n",
    "                p_flat = p.view(-1)\n",
    "                p_flat.copy_((1 - mu) * p_flat + mu * torch.tensor(corner[index:index+numel], dtype=torch.float32))\n",
    "                index += numel\n",
    "        losses.append(loss.item())\n",
    "        gradients.append(np.linalg.norm(gradient))  # 记录梯度的范数\n",
    "        parameters.append(model.state_dict().copy())\n",
    "        model.zero_grad()\n",
    "\n",
    "    min_loss_index = np.argmin(losses)\n",
    "    model.load_state_dict(parameters[min_loss_index])\n",
    "\n",
    "    # 后处理：将绝对值小于阈值的系数设为0\n",
    "    with torch.no_grad():\n",
    "        model.beta[torch.abs(model.beta) < threshold] = 0\n",
    "\n",
    "    return model, mean, std, losses[-1], calculate_mse(model, x, y)\n",
    "\n",
    "# 实验模块\n",
    "def run_experiments(N_values, epsilon_values, num_repeats=2):\n",
    "    \"\"\"\n",
    "    运行实验并保存结果。\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for N in N_values:\n",
    "        # 生成数据，并保存真实参数\n",
    "        true_params_path = f'true_parameters_N{N}.csv'\n",
    "        x, y, true_beta = generate_data(num_features, sigma_u, sigma_v, N, save_path=true_params_path)\n",
    "\n",
    "        # 划分训练集和测试集\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "        pd.DataFrame(np.hstack([x, y.reshape(-1, 1)]), columns=[f'x{i}' for i in range(num_features)] + ['y']).to_csv(f'data_{N}.csv', index=False)\n",
    "\n",
    "        # MLE 方法\n",
    "        beta_mle, lambda_mle, sigma_sq_mle, mse_mle, bic_mle, best_r = stochastic_frontier_mle_lasso_bic(x_train, y_train)\n",
    "        sse_mle = calculate_sse(beta_mle, true_beta)\n",
    "        fp_mle = calculate_fp(beta_mle, true_beta)\n",
    "        sr_mle = calculate_sr(beta_mle, true_beta)\n",
    "\n",
    "        results.append({\n",
    "            'N': N,\n",
    "            'epsilon': None,\n",
    "            'method': 'mle',\n",
    "            'beta': beta_mle,\n",
    "            'lambda': lambda_mle,\n",
    "            'sigma_sq': sigma_sq_mle,\n",
    "            'mse': mse_mle,\n",
    "            'loss': None,\n",
    "            'sse': sse_mle,\n",
    "            'fp': fp_mle,\n",
    "            'sr': sr_mle,\n",
    "            'hyperparams': {'best_r': best_r}\n",
    "        })\n",
    "\n",
    "        # 非私有和私有方法\n",
    "        for epsilon in epsilon_values:\n",
    "            for method in ['without_private', 'private']:\n",
    "                if method == 'private':\n",
    "                    model, _, _, loss, mse = train_model_private(x_train, y_train, num_features, epsilon=epsilon)\n",
    "                else:\n",
    "                    model, _, _, loss, mse = train_model_without_private(x_train, y_train, num_features)\n",
    "\n",
    "                beta_hat = model.beta.detach().numpy()\n",
    "                lambda_hat = torch.exp(model.log_lambda0).item()\n",
    "                sigma_sq_hat = torch.exp(model.log_sigma2).item()\n",
    "\n",
    "                # 计算 SSE, FP, SR\n",
    "                sse = calculate_sse(beta_hat, true_beta)\n",
    "                fp = calculate_fp(beta_hat, true_beta)\n",
    "                sr = calculate_sr(beta_hat, true_beta)\n",
    "\n",
    "                results.append({\n",
    "                    'N': N,\n",
    "                    'epsilon': epsilon,\n",
    "                    'method': method,\n",
    "                    'beta': beta_hat,\n",
    "                    'lambda': lambda_hat,\n",
    "                    'sigma_sq': sigma_sq_hat,\n",
    "                    'mse': mse,\n",
    "                    'loss': loss,\n",
    "                    'sse': sse,\n",
    "                    'fp': fp,\n",
    "                    'sr': sr,\n",
    "                    'hyperparams': {}\n",
    "                })\n",
    "\n",
    "    # 保存结果到 CSV\n",
    "    pd.DataFrame(results).to_csv('result.csv', index=False)\n",
    "\n",
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    # 参数设置\n",
    "    num_features = 100  # 特征数量\n",
    "    sigma_u = 0.3  # 非负噪声的标准差\n",
    "    sigma_v = 0.5  # 随机噪声的标准差\n",
    "    N_values = [500]  # 样本数量\n",
    "    epsilon_values = [1]  # 隐私预算\n",
    "\n",
    "    # 运行实验\n",
    "    run_experiments(N_values, epsilon_values)\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5399fb0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a4219cc",
   "metadata": {},
   "source": [
    "# 模块分割"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6f19527",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy.stats import halfnorm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "import seaborn as sns\n",
    "\n",
    "# Stochastic Frontier Model类\n",
    "class StochasticFrontierModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.beta = nn.Parameter(torch.tensor(num_features * [1.0], dtype=torch.float32))\n",
    "        self.log_sigma2 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.log_lambda0 = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def predict(self, x):\n",
    "        # 使用 torch.matmul 执行矩阵乘法\n",
    "        predictions = torch.matmul(x, self.beta)\n",
    "        return predictions\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        sigma2 = torch.exp(self.log_sigma2)\n",
    "        lambda0 = torch.exp(self.log_lambda0)\n",
    "        sigma = torch.sqrt(sigma2)\n",
    "        epsilon = y - torch.sum(x * self.beta, dim=1)\n",
    "\n",
    "        term1 = x.shape[0] * self.log_sigma2 / 2\n",
    "        term2 = -torch.sum(torch.log(torch.distributions.normal.Normal(0, 1).cdf(-epsilon * lambda0 / sigma) + 1e-10))\n",
    "        term3 = torch.sum(epsilon**2) / (2 * sigma2)\n",
    "\n",
    "        return (term1 + term2 + term3) / x.shape[0]\n",
    "\n",
    "# 数据生成模块\n",
    "def generate_data(num_features, sigma_u, sigma_v, N, save_path='true_parameters.csv'):\n",
    "    \"\"\"\n",
    "    生成数据，并保存真实的 beta、lambda、sigma_sq 等参数到 CSV 文件。\n",
    "    :param num_features: 特征数量\n",
    "    :param sigma_u: 非负噪声的标准差\n",
    "    :param sigma_v: 随机噪声的标准差\n",
    "    :param N: 样本数量\n",
    "    :param save_path: 保存真实参数的 CSV 文件路径\n",
    "    :return: x, y, true_beta\n",
    "    \"\"\"\n",
    "    # 生成稀疏的 beta 向量（num_features 维，只有 6 个非零系数，取值为 1 或 -1）\n",
    "    beta = np.zeros(num_features)\n",
    "    non_zero_indices = np.random.choice(num_features, 6, replace=False)  # 随机选择 6 个非零位置\n",
    "    beta[non_zero_indices] = np.random.choice([-1, 1], 6)  # 非零系数为 1 或 -1\n",
    "\n",
    "    # 生成特征数据 x\n",
    "    x = np.random.normal(0, 1, (N, num_features))  # num_features 维特征，服从标准正态分布\n",
    "\n",
    "    # 生成噪声 v 和 u\n",
    "    v = np.random.normal(0, sigma_v, N)  # 随机噪声 v\n",
    "    u = stats.halfnorm.rvs(loc=0, scale=sigma_u, size=N)  # 非负噪声 u\n",
    "\n",
    "    # 生成目标变量 y\n",
    "    y = x.dot(beta) + v - u\n",
    "\n",
    "    # 保存真实参数到 CSV 文件\n",
    "    true_params = {\n",
    "        'beta': beta,\n",
    "        'lambda': sigma_u / sigma_v,  # lambda = sigma_u / sigma_v\n",
    "        'sigma_sq': sigma_u**2 + sigma_v**2  # sigma^2 = sigma_u^2 + sigma_v^2\n",
    "    }\n",
    "    pd.DataFrame(true_params).to_csv(save_path, index=False)\n",
    "\n",
    "    # 保存生成的数据\n",
    "    data = np.hstack([x, y.reshape(-1, 1)])\n",
    "    pd.DataFrame(data, columns=[f'x{i}' for i in range(num_features)] + ['y']).to_csv('data.csv', index=False)\n",
    "\n",
    "    return x, y, beta\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2937ec57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # MLE 变量选择模块\n",
    "# def stochastic_frontier_mle_lasso_bic(x, y, r_range=np.logspace(-2, 4, 3), threshold=1e-3, max_iter=2):\n",
    "#     \"\"\"\n",
    "#     使用自适应 Lasso 惩罚的随机前沿模型进行变量选择和参数估计。\n",
    "#     :param x: 特征矩阵\n",
    "#     :param y: 目标变量\n",
    "#     :param r_range: Lasso 惩罚参数的范围\n",
    "#     :param threshold: 系数阈值，小于该值的系数设为 0\n",
    "#     :param max_iter: 最大迭代次数\n",
    "#     :return: 估计的 beta, lambda, sigma^2, MSE, BIC, 最优 r\n",
    "#     \"\"\"\n",
    "#     x_df = pd.DataFrame(x)\n",
    "#     y_series = pd.Series(y)\n",
    "\n",
    "#     def calculate_bic(r, x_df, y_series):\n",
    "#         # 第一次 Lasso 估计\n",
    "#         lasso = Lasso(alpha=r)\n",
    "#         lasso.fit(x_df, y_series)\n",
    "#         beta_init = lasso.coef_\n",
    "\n",
    "#         # 计算自适应 Lasso 权重\n",
    "#         w = np.zeros_like(beta_init)\n",
    "#         for j in range(len(beta_init)):\n",
    "#             if np.abs(beta_init[j]) > threshold:\n",
    "#                 w[j] = 1 / np.abs(beta_init[j])\n",
    "#             else:\n",
    "#                 w[j] = 0\n",
    "\n",
    "#         def logLikFun(param):\n",
    "#             parlab = param[:-2]\n",
    "#             parsigmaSq = param[-2]\n",
    "#             parlambda = param[-1]\n",
    "#             epsilon = y_series - np.dot(x_df, parlab)\n",
    "#             penalty = r * np.sum(w * np.abs(parlab))\n",
    "#             return -np.sum(0.5 * np.log(parsigmaSq) + 0.5 / parsigmaSq * epsilon**2 -\n",
    "#                            norm.logcdf(-epsilon * parlambda / np.sqrt(parsigmaSq))) + penalty\n",
    "\n",
    "#         # 使用最小二乘法获取初始参数\n",
    "#         ols = sm.OLS(y_series, x_df).fit()\n",
    "#         init_params = np.append(ols.params.values, [0.5, sum(ols.resid**2) / (len(y_series) - len(ols.params))])\n",
    "\n",
    "#         # 极大似然估计\n",
    "#         result = minimize(lambda params: -logLikFun(params), init_params, method='Nelder-Mead')\n",
    "\n",
    "#         # 提取估计的参数\n",
    "#         beta = result.x[:-2]\n",
    "#         sigma_sq = result.x[-2]\n",
    "#         lambda_ = result.x[-1]\n",
    "\n",
    "#         # 后处理：将绝对值小于阈值的系数设为 0\n",
    "#         beta[np.abs(beta) < threshold] = 0\n",
    "\n",
    "#         # 计算对数似然值\n",
    "#         log_lik = -logLikFun(result.x)\n",
    "\n",
    "#         # 计算 BIC\n",
    "#         n = len(y_series)\n",
    "#         k = np.sum(beta != 0) + 2\n",
    "#         bic = -2 * log_lik + k * np.log(n)\n",
    "\n",
    "#         return bic, beta, lambda_, sigma_sq\n",
    "\n",
    "#     # 初始化\n",
    "#     best_bic = np.inf\n",
    "#     best_r = None\n",
    "#     best_beta = None\n",
    "#     best_lambda = None\n",
    "#     best_sigma_sq = None\n",
    "#     best_features = None\n",
    "\n",
    "#     # 遍历 r_range，选择使 BIC 最小的 r\n",
    "#     for r in r_range:\n",
    "#         # 初始估计\n",
    "#         bic, beta, lambda_, sigma_sq = calculate_bic(r, x_df, y_series)\n",
    "\n",
    "#         # 迭代筛选和重新估计\n",
    "#         for _ in range(max_iter):\n",
    "#             # 筛选出非零特征\n",
    "#             selected_features = np.abs(beta) >= threshold\n",
    "#             if not np.any(selected_features):\n",
    "#                 break\n",
    "\n",
    "#             # 确保 selected_features 的长度与 x_df 的列数一致\n",
    "#             if len(selected_features) != x_df.shape[1]:\n",
    "#                 selected_features = np.append(selected_features, [False] * (x_df.shape[1] - len(selected_features)))\n",
    "\n",
    "#             # 使用筛选后的特征重新估计\n",
    "#             x_filtered = x_df.loc[:, selected_features]\n",
    "#             bic_new, beta_new, lambda_new, sigma_sq_new = calculate_bic(r, x_filtered, y_series)\n",
    "\n",
    "#             # 如果 BIC 没有改善，停止迭代\n",
    "#             if bic_new >= bic:\n",
    "#                 break\n",
    "\n",
    "#             # 更新结果\n",
    "#             bic, beta, lambda_, sigma_sq = bic_new, beta_new, lambda_new, sigma_sq_new\n",
    "\n",
    "#         # 记录最优结果\n",
    "#         if bic < best_bic:\n",
    "#             best_bic = bic\n",
    "#             best_r = r\n",
    "#             best_beta = beta\n",
    "#             best_lambda = lambda_\n",
    "#             best_sigma_sq = sigma_sq\n",
    "#             best_features = selected_features\n",
    "\n",
    "#     # 确保 best_features 的长度与 best_beta 的长度一致\n",
    "#     if len(best_features) != len(best_beta):\n",
    "#         best_features = np.abs(best_beta) >= threshold\n",
    "\n",
    "#     # 计算 MSE\n",
    "#     epsilon = y_series - np.dot(x_df.loc[:, best_features], best_beta[best_features])\n",
    "#     mse = np.mean(epsilon**2)\n",
    "\n",
    "#     return best_beta, best_lambda, best_sigma_sq, mse, best_bic, best_r\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "85be8440",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 非私有和私有方法模块\n",
    "def train_model_without_private(x, y, num_features, num_iters=3000, constraint=100, minibatch_size=50, threshold=1e-3):\n",
    "    \"\"\"\n",
    "    训练非私有模型。\n",
    "    \"\"\"\n",
    "    x, mean, std = standardize_data(x)\n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    model = StochasticFrontierModel(num_features=num_features)\n",
    "    losses = []\n",
    "    gradients = []\n",
    "    parameters = []\n",
    "\n",
    "    for i in tqdm(range(1, num_iters + 1), desc=\"Training without privacy\"):\n",
    "        minibatch_indices = np.random.choice(x.shape[0], minibatch_size, replace=True)\n",
    "        minibatch_x = x[minibatch_indices]\n",
    "        minibatch_y = y[minibatch_indices]\n",
    "        loss = model(minibatch_x, minibatch_y)\n",
    "        loss.backward()\n",
    "        gradient = torch.cat([p.grad.flatten() for p in model.parameters()]).detach().numpy()\n",
    "        pos_alphas = compute_alpha(constraint, gradient, model)\n",
    "        neg_alphas = compute_alpha(-constraint, gradient, model)\n",
    "        alphas = pos_alphas + neg_alphas\n",
    "        min_alpha, size, corner_num = min(alphas, key=lambda x: x[0])\n",
    "        corner = np.zeros(sum(p.numel() for p in model.parameters()))\n",
    "        corner[corner_num] = size\n",
    "        mu = 2 / (i + 2)\n",
    "        with torch.no_grad():\n",
    "            index = 0\n",
    "            for p in model.parameters():\n",
    "                numel = p.numel()\n",
    "                p_flat = p.view(-1)\n",
    "                p_flat.copy_((1 - mu) * p_flat + mu * torch.tensor(corner[index:index+numel], dtype=torch.float32))\n",
    "                index += numel\n",
    "        losses.append(loss.item())\n",
    "        gradients.append(np.linalg.norm(gradient))  # 记录梯度的范数\n",
    "        parameters.append(model.state_dict().copy())\n",
    "        model.zero_grad()\n",
    "\n",
    "    min_loss_index = np.argmin(losses)\n",
    "    model.load_state_dict(parameters[min_loss_index])\n",
    "\n",
    "    # 后处理：将绝对值小于阈值的系数设为0\n",
    "    with torch.no_grad():\n",
    "        model.beta[torch.abs(model.beta) < threshold] = 0\n",
    "\n",
    "    return model, mean, std, losses[-1], calculate_mse(model, x, y)\n",
    "\n",
    "def train_model_private(x, y, num_features, num_iters=3000, constraint=100, minibatch_size=50, lipschitz=1, epsilon=0.1, delta=1e-5, threshold=1e-3):\n",
    "    \"\"\"\n",
    "    训练私有模型。\n",
    "    \"\"\"\n",
    "    x, mean, std = standardize_data(x)\n",
    "    x = torch.tensor(x, dtype=torch.float32)\n",
    "    y = torch.tensor(y, dtype=torch.float32)\n",
    "    model = StochasticFrontierModel(num_features=num_features)\n",
    "    n = x.shape[0]\n",
    "    m = sum(p.numel() for p in model.parameters())\n",
    "    losses = []\n",
    "    gradients = []\n",
    "    parameters = []\n",
    "    noise_para = lipschitz * constraint * math.sqrt(8 * num_iters * math.log(1 / delta)) / (n * epsilon)\n",
    "\n",
    "    for i in tqdm(range(1, num_iters + 1), desc=\"Training with privacy\"):\n",
    "        minibatch_indices = np.random.choice(x.shape[0], minibatch_size, replace=True)\n",
    "        minibatch_x = x[minibatch_indices]\n",
    "        minibatch_y = y[minibatch_indices]\n",
    "        loss = model(minibatch_x, minibatch_y)\n",
    "        loss.backward()\n",
    "        gradient = torch.cat([p.grad.flatten() for p in model.parameters()]).detach().numpy()\n",
    "        pos_alphas = compute_alpha_private(constraint, gradient, model, noise_para)\n",
    "        neg_alphas = compute_alpha_private(-constraint, gradient, model, noise_para)\n",
    "        alphas = pos_alphas + neg_alphas\n",
    "        min_alpha, size, corner_num = min(alphas, key=lambda x: x[0])\n",
    "        corner = np.zeros(m)\n",
    "        corner[corner_num] = size\n",
    "        mu = 2 / (i + 2)\n",
    "        with torch.no_grad():\n",
    "            index = 0\n",
    "            for p in model.parameters():\n",
    "                numel = p.numel()\n",
    "                p_flat = p.view(-1)\n",
    "                p_flat.copy_((1 - mu) * p_flat + mu * torch.tensor(corner[index:index+numel], dtype=torch.float32))\n",
    "                index += numel\n",
    "        losses.append(loss.item())\n",
    "        gradients.append(np.linalg.norm(gradient))  # 记录梯度的范数\n",
    "        parameters.append(model.state_dict().copy())\n",
    "        model.zero_grad()\n",
    "\n",
    "    min_loss_index = np.argmin(losses)\n",
    "    model.load_state_dict(parameters[min_loss_index])\n",
    "\n",
    "    # 后处理：将绝对值小于阈值的系数设为0\n",
    "    with torch.no_grad():\n",
    "        model.beta[torch.abs(model.beta) < threshold] = 0\n",
    "\n",
    "    return model, mean, std, losses[-1], calculate_mse(model, x, y)\n",
    "def compute_alpha( corner_size, gradient, model):\n",
    "    alpha = gradient * corner_size\n",
    "    corner_size = (np.ones(sum(p.numel() for p in model.parameters())) * corner_size).tolist()\n",
    "    corner_num = np.arange(sum(p.numel() for p in model.parameters())).tolist()\n",
    "    return list(zip(alpha, corner_size, corner_num))\n",
    "\n",
    "def compute_alpha_private( corner_size, gradient, model, noise_para):\n",
    "    \n",
    "    alpha = gradient * corner_size\n",
    "    noise = np.random.laplace(scale=noise_para, size=sum(p.numel() for p in model.parameters()))\n",
    "    alpha = alpha + noise\n",
    "    corner_size = (np.ones(sum(p.numel() for p in model.parameters())) * corner_size).tolist()\n",
    "    corner_num = np.arange(sum(p.numel() for p in model.parameters())).tolist()\n",
    "    return list(zip(alpha, corner_size, corner_num))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "023bd6b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 实验模块\n",
    "def run_experiments(N_values, epsilon_values, num_repeats=2):\n",
    "    \"\"\"\n",
    "    运行实验并保存结果。\n",
    "    \"\"\"\n",
    "    results = []\n",
    "    for N in N_values:\n",
    "        # 生成数据，并保存真实参数\n",
    "        true_params_path = f'true_parameters_N{N}.csv'\n",
    "        x, y, true_beta = generate_data(num_features, sigma_u, sigma_v, N, save_path=true_params_path)\n",
    "\n",
    "        # 划分训练集和测试集\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "        pd.DataFrame(np.hstack([x, y.reshape(-1, 1)]), columns=[f'x{i}' for i in range(num_features)] + ['y']).to_csv(f'data_{N}.csv', index=False)\n",
    "\n",
    "        # MLE 方法\n",
    "        beta_mle, lambda_mle, sigma_sq_mle, mse_mle, bic_mle, best_r = stochastic_frontier_mle_lasso_bic(x_train, y_train)\n",
    "        sse_mle = calculate_sse(beta_mle, true_beta)\n",
    "        fp_mle = calculate_fp(beta_mle, true_beta)\n",
    "        sr_mle = calculate_sr(beta_mle, true_beta)\n",
    "\n",
    "        results.append({\n",
    "            'N': N,\n",
    "            'epsilon': None,\n",
    "            'method': 'mle',\n",
    "            'beta': beta_mle,\n",
    "            'lambda': lambda_mle,\n",
    "            'sigma_sq': sigma_sq_mle,\n",
    "            'mse': mse_mle,\n",
    "            'loss': None,\n",
    "            'sse': sse_mle,\n",
    "            'fp': fp_mle,\n",
    "            'sr': sr_mle,\n",
    "            'hyperparams': {'best_r': best_r}\n",
    "        })\n",
    "\n",
    "        # 非私有和私有方法\n",
    "        for epsilon in epsilon_values:\n",
    "            for method in ['without_private', 'private']:\n",
    "                if method == 'private':\n",
    "                    model, _, _, loss, mse = train_model_private(x_train, y_train, num_features, epsilon=epsilon)\n",
    "                else:\n",
    "                    model, _, _, loss, mse = train_model_without_private(x_train, y_train, num_features)\n",
    "\n",
    "                beta_hat = model.beta.detach().numpy()\n",
    "                lambda_hat = torch.exp(model.log_lambda0).item()\n",
    "                sigma_sq_hat = torch.exp(model.log_sigma2).item()\n",
    "\n",
    "                # 计算 SSE, FP, SR\n",
    "                sse = calculate_sse(beta_hat, true_beta)\n",
    "                fp = calculate_fp(beta_hat, true_beta)\n",
    "                sr = calculate_sr(beta_hat, true_beta)\n",
    "\n",
    "                results.append({\n",
    "                    'N': N,\n",
    "                    'epsilon': epsilon,\n",
    "                    'method': method,\n",
    "                    'beta': beta_hat,\n",
    "                    'lambda': lambda_hat,\n",
    "                    'sigma_sq': sigma_sq_hat,\n",
    "                    'mse': mse,\n",
    "                    'loss': loss,\n",
    "                    'sse': sse,\n",
    "                    'fp': fp,\n",
    "                    'sr': sr,\n",
    "                    'hyperparams': {}\n",
    "                })\n",
    "\n",
    "    # 保存结果到 CSV\n",
    "    pd.DataFrame(results).to_csv('result.csv', index=False)\n",
    "\n",
    "\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a5204249",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_frontier_mle_lasso_bic(x, y, r_range=np.logspace(-2, 4, 3), threshold=1e-3, max_iter=2):\n",
    "    \"\"\"\n",
    "    使用自适应 Lasso 惩罚的随机前沿模型进行变量选择和参数估计。\n",
    "    :param x: 特征矩阵\n",
    "    :param y: 目标变量\n",
    "    :param r_range: Lasso 惩罚参数的范围\n",
    "    :param threshold: 系数阈值，小于该值的系数设为 0\n",
    "    :param max_iter: 最大迭代次数\n",
    "    :return: 估计的 beta, lambda, sigma^2, MSE, BIC, 最优 r\n",
    "    \"\"\"\n",
    "    x_df = pd.DataFrame(x)\n",
    "    y_series = pd.Series(y)\n",
    "\n",
    "    def calculate_bic(r, x_df, y_series):\n",
    "        # 第一次 Lasso 估计\n",
    "        lasso = Lasso(alpha=r)\n",
    "        lasso.fit(x_df, y_series)\n",
    "        beta_init = lasso.coef_\n",
    "\n",
    "        # 计算自适应 Lasso 权重\n",
    "        w = np.zeros_like(beta_init)\n",
    "        for j in range(len(beta_init)):\n",
    "            if np.abs(beta_init[j]) > threshold:\n",
    "                w[j] = 1 / np.abs(beta_init[j])\n",
    "            else:\n",
    "                w[j] = 0\n",
    "\n",
    "        def logLikFun(param):\n",
    "            parlab = param[:-2]\n",
    "            parsigmaSq = param[-2]\n",
    "            parlambda = param[-1]\n",
    "            epsilon = y_series - np.dot(x_df, parlab)\n",
    "            penalty = r * np.sum(w * np.abs(parlab))\n",
    "            return -np.sum(0.5 * np.log(parsigmaSq) + 0.5 / parsigmaSq * epsilon**2 -\n",
    "                           norm.logcdf(-epsilon * parlambda / np.sqrt(parsigmaSq))) + penalty\n",
    "\n",
    "        # 使用最小二乘法获取初始参数\n",
    "        ols = sm.OLS(y_series, x_df).fit()\n",
    "        init_params = np.append(ols.params.values, [0.5, sum(ols.resid**2) / (len(y_series) - len(ols.params))])\n",
    "\n",
    "        # 极大似然估计\n",
    "        result = minimize(lambda params: -logLikFun(params), init_params, method='Nelder-Mead')\n",
    "\n",
    "        # 提取估计的参数\n",
    "        beta = result.x[:-2]\n",
    "        sigma_sq = result.x[-2]\n",
    "        lambda_ = result.x[-1]\n",
    "\n",
    "        # 后处理：将绝对值小于阈值的系数设为 0\n",
    "        beta[np.abs(beta) < threshold] = 0\n",
    "\n",
    "        # 计算对数似然值\n",
    "        log_lik = -logLikFun(result.x)\n",
    "\n",
    "        # 计算 BIC\n",
    "        n = len(y_series)\n",
    "        k = np.sum(beta != 0) + 2\n",
    "        bic = -2 * log_lik + k * np.log(n)\n",
    "\n",
    "        return bic, beta, lambda_, sigma_sq\n",
    "\n",
    "    # 初始化\n",
    "    best_bic = np.inf\n",
    "    best_r = None\n",
    "    best_beta = None\n",
    "    best_lambda = None\n",
    "    best_sigma_sq = None\n",
    "    best_features = None\n",
    "\n",
    "    # 遍历 r_range，选择使 BIC 最小的 r\n",
    "    for r in r_range:\n",
    "        # 初始估计\n",
    "        bic, beta, lambda_, sigma_sq = calculate_bic(r, x_df, y_series)\n",
    "\n",
    "        # 迭代筛选和重新估计\n",
    "        for _ in range(max_iter):\n",
    "            # 筛选出非零特征\n",
    "            selected_features = np.abs(beta) >= threshold\n",
    "            if not np.any(selected_features):\n",
    "                break\n",
    "\n",
    "            # 确保 selected_features 的长度与 x_df 的列数一致\n",
    "            if len(selected_features) != x_df.shape[1]:\n",
    "                selected_features = np.append(selected_features, [False] * (x_df.shape[1] - len(selected_features)))\n",
    "\n",
    "            # 使用筛选后的特征重新估计\n",
    "            x_filtered = x_df.loc[:, selected_features]\n",
    "            bic_new, beta_new, lambda_new, sigma_sq_new = calculate_bic(r, x_filtered, y_series)\n",
    "\n",
    "            # 如果 BIC 没有改善，停止迭代\n",
    "            if bic_new >= bic:\n",
    "                break\n",
    "\n",
    "            # 更新结果\n",
    "            bic, beta, lambda_, sigma_sq = bic_new, beta_new, lambda_new, sigma_sq_new\n",
    "\n",
    "        # 记录最优结果\n",
    "        if bic < best_bic:\n",
    "            best_bic = bic\n",
    "            best_r = r\n",
    "            best_beta = beta\n",
    "            best_lambda = lambda_\n",
    "            best_sigma_sq = sigma_sq\n",
    "            best_features = selected_features\n",
    "\n",
    "    # 确保 best_features 的长度与 x_df 的列数一致\n",
    "    if len(best_features) != x_df.shape[1]:\n",
    "        best_features = np.append(best_features, [False] * (x_df.shape[1] - len(best_features)))\n",
    "\n",
    "    # 计算 MSE\n",
    "    epsilon = y_series - np.dot(x_df.loc[:, best_features], best_beta)\n",
    "    mse = np.mean(epsilon**2)\n",
    "\n",
    "    return best_beta, best_lambda, best_sigma_sq, mse, best_bic, best_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c50f56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def calculate_sse( beta_hat, beta_true):\n",
    "#     return np.sum((beta_hat - beta_true) ** 2)\n",
    "\n",
    "# def calculate_fp( beta_hat, beta_true):\n",
    "#     return np.sum((beta_true == 0) & (beta_hat != 0))\n",
    "\n",
    "# def calculate_sr( beta_hat, beta_true, threshold=1e-3):\n",
    "#     return np.linalg.norm(beta_hat - beta_true) <= threshold\n",
    "def calculate_sse(beta_hat, beta_true):\n",
    "    \"\"\"\n",
    "    计算 SSE（Sum of Squared Errors）。\n",
    "    :param beta_hat: 估计的 beta\n",
    "    :param beta_true: 真实的 beta\n",
    "    :return: SSE\n",
    "    \"\"\"\n",
    "    # 将 beta_hat 的长度扩展到与 beta_true 相同\n",
    "    if len(beta_hat) < len(beta_true):\n",
    "        beta_hat = np.pad(beta_hat, (0, len(beta_true) - len(beta_hat)), mode='constant')\n",
    "    return np.sum((beta_hat - beta_true) ** 2)\n",
    "\n",
    "def calculate_fp(beta_hat, beta_true):\n",
    "    \"\"\"\n",
    "    计算 FP（False Positives）。\n",
    "    :param beta_hat: 估计的 beta\n",
    "    :param beta_true: 真实的 beta\n",
    "    :return: FP\n",
    "    \"\"\"\n",
    "    # 将 beta_hat 的长度扩展到与 beta_true 相同\n",
    "    if len(beta_hat) < len(beta_true):\n",
    "        beta_hat = np.pad(beta_hat, (0, len(beta_true) - len(beta_hat)), mode='constant')\n",
    "    return np.sum((beta_true == 0) & (beta_hat != 0))\n",
    "\n",
    "def calculate_sr(beta_hat, beta_true, threshold=1e-3):\n",
    "    \"\"\"\n",
    "    计算 SR（Selection Rate）。\n",
    "    :param beta_hat: 估计的 beta\n",
    "    :param beta_true: 真实的 beta\n",
    "    :param threshold: 阈值\n",
    "    :return: SR\n",
    "    \"\"\"\n",
    "    # 将 beta_hat 的长度扩展到与 beta_true 相同\n",
    "    if len(beta_hat) < len(beta_true):\n",
    "        beta_hat = np.pad(beta_hat, (0, len(beta_true) - len(beta_hat)), mode='constant')\n",
    "    return np.linalg.norm(beta_hat - beta_true) <= threshold\n",
    "def standardize_data( x):\n",
    "\n",
    "    mean = np.mean(x[:, 1:], axis=0)\n",
    "    std = np.std(x[:, 1:], axis=0)\n",
    "    x_standardized = np.column_stack([x[:, 0], (x[:, 1:] - mean) / std])\n",
    "    return x_standardized, np.insert(mean, 0, 0), np.insert(std, 0, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc35a9e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 主程序\n",
    "if __name__ == \"__main__\":\n",
    "    # 参数设置\n",
    "    num_features = 100  # 特征数量\n",
    "    sigma_u = 0.3  # 非负噪声的标准差\n",
    "    sigma_v = 0.5  # 随机噪声的标准差\n",
    "    N_values = [500]  # 样本数量\n",
    "    epsilon_values = [1]  # 隐私预算\n",
    "\n",
    "    # 运行实验\n",
    "    run_experiments(N_values, epsilon_values)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
