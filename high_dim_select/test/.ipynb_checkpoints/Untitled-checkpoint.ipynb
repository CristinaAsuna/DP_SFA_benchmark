{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05613cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import optuna\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import numpy as np\n",
    "from scipy.stats import halfnorm\n",
    "import scipy.stats as stats\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm\n",
    "from scipy.optimize import minimize\n",
    "import statsmodels.api as sm\n",
    "import pandas as pd\n",
    "import math\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.linear_model import Lasso\n",
    "import seaborn as sns\n",
    "\n",
    "# Stochastic Frontier Model类\n",
    "class StochasticFrontierModel(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super().__init__()\n",
    "        self.beta = nn.Parameter(torch.tensor(num_features * [1.0], dtype=torch.float32))\n",
    "        self.log_sigma2 = nn.Parameter(torch.tensor(0.0))\n",
    "        self.log_lambda0 = nn.Parameter(torch.tensor(0.0))\n",
    "\n",
    "    def predict(self, x):\n",
    "        # 使用 torch.matmul 执行矩阵乘法\n",
    "        predictions = torch.matmul(x, self.beta)\n",
    "        return predictions\n",
    "\n",
    "    def forward(self, x, y):\n",
    "        sigma2 = torch.exp(self.log_sigma2)\n",
    "        lambda0 = torch.exp(self.log_lambda0)\n",
    "        sigma = torch.sqrt(sigma2)\n",
    "        epsilon = y - torch.sum(x * self.beta, dim=1)\n",
    "\n",
    "        term1 = x.shape[0] * self.log_sigma2 / 2\n",
    "        term2 = -torch.sum(torch.log(torch.distributions.normal.Normal(0, 1).cdf(-epsilon * lambda0 / sigma) + 1e-10))\n",
    "        term3 = torch.sum(epsilon**2) / (2 * sigma2)\n",
    "\n",
    "        return (term1 + term2 + term3) / x.shape[0]\n",
    "\n",
    "class StochasticFrontierAnalysis:\n",
    "    def __init__(self, num_features, sigma_u, sigma_v):\n",
    "        self.num_features = num_features\n",
    "        self.sigma_u = sigma_u\n",
    "        self.sigma_v = sigma_v\n",
    "\n",
    "    def standardize_data(self, x):\n",
    "        mean = np.mean(x[:, 1:], axis=0)\n",
    "        std = np.std(x[:, 1:], axis=0)\n",
    "        x_standardized = np.column_stack([x[:, 0], (x[:, 1:] - mean) / std])\n",
    "        return x_standardized, np.insert(mean, 0, 0), np.insert(std, 0, 1)\n",
    "\n",
    "    def generate_data(self, N, save_path='true_parameters.csv'):\n",
    "        \"\"\"\n",
    "        生成数据，并保存真实的 beta、lambda、sigma_sq 等参数到 CSV 文件。\n",
    "        :param N: 样本数量\n",
    "        :param save_path: 保存真实参数的 CSV 文件路径\n",
    "        :return: x, y, true_beta\n",
    "        \"\"\"\n",
    "        # 生成稀疏的 beta 向量（500 维，只有 6 个非零系数，取值为 1 或 -1）\n",
    "        beta = np.zeros(self.num_features)\n",
    "        non_zero_indices = np.random.choice(self.num_features, 6, replace=False)  # 随机选择 6 个非零位置\n",
    "        beta[non_zero_indices] = np.random.choice([-1, 1], 6)  # 非零系数为 1 或 -1\n",
    "\n",
    "        # 生成特征数据 x\n",
    "        x = np.random.normal(0, 1, (N, self.num_features))  # 500 维特征，服从标准正态分布\n",
    "\n",
    "        # 生成噪声 v 和 u\n",
    "        v = np.random.normal(0, self.sigma_v, N)  # 随机噪声 v\n",
    "        u = stats.halfnorm.rvs(loc=0, scale=self.sigma_u, size=N)  # 非负噪声 u\n",
    "\n",
    "        # 生成目标变量 y\n",
    "        y = x.dot(beta) + v - u\n",
    "\n",
    "        # 保存真实参数到 CSV 文件\n",
    "        true_params = {\n",
    "            'beta': beta,\n",
    "            'lambda': self.sigma_u / self.sigma_v,  # lambda = sigma_u / sigma_v\n",
    "            'sigma_sq': self.sigma_u**2 + self.sigma_v**2  # sigma^2 = sigma_u^2 + sigma_v^2\n",
    "        }\n",
    "        pd.DataFrame(true_params).to_csv(save_path, index=False)\n",
    "\n",
    "        return x, y, beta\n",
    "\n",
    "    def stochastic_frontier_mle_lasso_bic(self, x, y, r_range=np.logspace(-2, 4, 20), threshold=1e-3, max_iter=10):\n",
    "        \"\"\"\n",
    "        使用自适应Lasso惩罚的随机前沿模型进行变量选择和参数估计，并进行后处理筛选和重新估计。\n",
    "        :param x: 特征矩阵\n",
    "        :param y: 目标变量\n",
    "        :param r_range: Lasso惩罚参数的范围\n",
    "        :param threshold: 系数阈值，小于该值的系数设为0\n",
    "        :param max_iter: 最大迭代次数\n",
    "        :return: 估计的beta, lambda, sigma^2, MSE, BIC, 最优r\n",
    "        \"\"\"\n",
    "        x_df = pd.DataFrame(x)\n",
    "        y_series = pd.Series(y)\n",
    "\n",
    "        def calculate_bic(r, x_df, y_series):\n",
    "            # 第一次Lasso估计\n",
    "            lasso = Lasso(alpha=r)\n",
    "            lasso.fit(x_df, y_series)\n",
    "            beta_init = lasso.coef_\n",
    "\n",
    "            # 计算自适应Lasso权重\n",
    "            w = np.zeros_like(beta_init)\n",
    "            for j in range(len(beta_init)):\n",
    "                if np.abs(beta_init[j]) > threshold:  # 使用阈值判断是否为非零系数\n",
    "                    w[j] = 1 / np.abs(beta_init[j])\n",
    "                else:\n",
    "                    w[j] = 0  # 对接近0的系数赋予0权重\n",
    "\n",
    "            def logLikFun(param):\n",
    "                parlab = param[:-2]\n",
    "                parsigmaSq = param[-2]\n",
    "                parlambda = param[-1]\n",
    "                epsilon = y_series - np.dot(x_df, parlab)\n",
    "                # 添加自适应Lasso惩罚项\n",
    "                penalty = r * np.sum(w * np.abs(parlab))\n",
    "                return -np.sum(0.5 * np.log(parsigmaSq) + 0.5 / parsigmaSq * epsilon**2 -\n",
    "                               norm.logcdf(-epsilon * parlambda / np.sqrt(parsigmaSq))) + penalty\n",
    "\n",
    "            # 使用最小二乘法获取初始参数\n",
    "            ols = sm.OLS(y_series, x_df).fit()\n",
    "            init_params = np.append(ols.params.values, [0.5, sum(ols.resid**2) / (len(y_series) - len(ols.params))])\n",
    "\n",
    "            # 极大似然估计\n",
    "            result = minimize(lambda params: -logLikFun(params), init_params, method='Nelder-Mead')\n",
    "\n",
    "            # 提取估计的参数\n",
    "            beta = result.x[:-2]  # 提取 beta 参数\n",
    "            sigma_sq = result.x[-2]  # 提取 sigma^2\n",
    "            lambda_ = result.x[-1]  # 提取 lambda\n",
    "\n",
    "            # 后处理：将绝对值小于阈值的系数设为0\n",
    "            beta[np.abs(beta) < threshold] = 0\n",
    "\n",
    "            # 计算对数似然值\n",
    "            log_lik = -logLikFun(result.x)\n",
    "\n",
    "            # 计算BIC\n",
    "            n = len(y_series)  # 样本数量\n",
    "            k = np.sum(beta != 0) + 2  # 非零参数数量（beta + sigma_sq + lambda）\n",
    "            bic = -2 * log_lik + k * np.log(n)\n",
    "\n",
    "            return bic, beta, lambda_, sigma_sq\n",
    "\n",
    "        # 初始化\n",
    "        best_bic = np.inf\n",
    "        best_r = None\n",
    "        best_beta = None\n",
    "        best_lambda = None\n",
    "        best_sigma_sq = None\n",
    "        best_features = None\n",
    "\n",
    "        # 遍历 r_range，选择使BIC最小的 r\n",
    "        for r in r_range:\n",
    "            # 初始估计\n",
    "            bic, beta, lambda_, sigma_sq = calculate_bic(r, x_df, y_series)\n",
    "\n",
    "            # 迭代筛选和重新估计\n",
    "            for _ in range(max_iter):\n",
    "                # 筛选出非零特征\n",
    "                selected_features = np.abs(beta) >= threshold\n",
    "                if not np.any(selected_features):\n",
    "                    break  # 如果所有特征都被筛除，停止迭代\n",
    "\n",
    "                # 确保 selected_features 的长度与 x_df 的列数一致\n",
    "                if len(selected_features) != x_df.shape[1]:\n",
    "                    selected_features = np.append(selected_features, [False] * (x_df.shape[1] - len(selected_features)))\n",
    "\n",
    "                # 使用筛选后的特征重新估计\n",
    "                x_filtered = x_df.loc[:, selected_features]\n",
    "                bic_new, beta_new, lambda_new, sigma_sq_new = calculate_bic(r, x_filtered, y_series)\n",
    "\n",
    "                # 如果BIC没有改善，停止迭代\n",
    "                if bic_new >= bic:\n",
    "                    break\n",
    "\n",
    "                # 更新结果\n",
    "                bic, beta, lambda_, sigma_sq = bic_new, beta_new, lambda_new, sigma_sq_new\n",
    "\n",
    "            # 记录最优结果\n",
    "            if bic < best_bic:\n",
    "                best_bic = bic\n",
    "                best_r = r\n",
    "                best_beta = beta\n",
    "                best_lambda = lambda_\n",
    "                best_sigma_sq = sigma_sq\n",
    "                best_features = selected_features\n",
    "\n",
    "        # 计算 MSE\n",
    "        epsilon = y_series - np.dot(x_df.loc[:, best_features], best_beta[best_features])\n",
    "        mse = np.mean(epsilon**2)\n",
    "\n",
    "        return best_beta, best_lambda, best_sigma_sq, mse, best_bic, best_r\n",
    "\n",
    "    def train_model_without_private(self, x, y, num_iters=3000, constraint=100, minibatch_size=50, threshold=1e-3):\n",
    "        x, mean, std = self.standardize_data(x)\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        model = StochasticFrontierModel(num_features=self.num_features)\n",
    "        losses = []\n",
    "        gradients = []\n",
    "        parameters = []\n",
    "\n",
    "        for i in tqdm(range(1, num_iters + 1), desc=\"Training without privacy\"):\n",
    "            minibatch_indices = np.random.choice(x.shape[0], minibatch_size, replace=True)\n",
    "            minibatch_x = x[minibatch_indices]\n",
    "            minibatch_y = y[minibatch_indices]\n",
    "            loss = model(minibatch_x, minibatch_y)\n",
    "            loss.backward()\n",
    "            gradient = torch.cat([p.grad.flatten() for p in model.parameters()]).detach().numpy()\n",
    "            pos_alphas = self.compute_alpha(constraint, gradient, model)\n",
    "            neg_alphas = self.compute_alpha(-constraint, gradient, model)\n",
    "            alphas = pos_alphas + neg_alphas\n",
    "            min_alpha, size, corner_num = min(alphas, key=lambda x: x[0])\n",
    "            corner = np.zeros(sum(p.numel() for p in model.parameters()))\n",
    "            corner[corner_num] = size\n",
    "            mu = 2 / (i + 2)\n",
    "            with torch.no_grad():\n",
    "                index = 0\n",
    "                for p in model.parameters():\n",
    "                    numel = p.numel()\n",
    "                    p_flat = p.view(-1)\n",
    "                    p_flat.copy_((1 - mu) * p_flat + mu * torch.tensor(corner[index:index+numel], dtype=torch.float32))\n",
    "                    index += numel\n",
    "            losses.append(loss.item())\n",
    "            gradients.append(np.linalg.norm(gradient))  # 记录梯度的范数\n",
    "            parameters.append(model.state_dict().copy())\n",
    "            model.zero_grad()\n",
    "\n",
    "        min_loss_index = np.argmin(losses)\n",
    "        model.load_state_dict(parameters[min_loss_index])\n",
    "\n",
    "        # 后处理：将绝对值小于阈值的系数设为0\n",
    "        with torch.no_grad():\n",
    "            model.beta[torch.abs(model.beta) < threshold] = 0\n",
    "\n",
    "        return model, mean, std, losses[-1], self.calculate_mse(model, x, y)\n",
    "\n",
    "    def train_model_private(self, x, y, num_iters=3000, constraint=100, minibatch_size=50, lipschitz=1, epsilon=0.1, delta=1e-5, threshold=1e-3):\n",
    "        x, mean, std = self.standardize_data(x)\n",
    "        x = torch.tensor(x, dtype=torch.float32)\n",
    "        y = torch.tensor(y, dtype=torch.float32)\n",
    "        model = StochasticFrontierModel(num_features=self.num_features)\n",
    "        n = x.shape[0]\n",
    "        m = sum(p.numel() for p in model.parameters())\n",
    "        losses = []\n",
    "        gradients = []\n",
    "        parameters = []\n",
    "        noise_para = lipschitz * constraint * math.sqrt(8 * num_iters * math.log(1 / delta)) / (n * epsilon)\n",
    "\n",
    "        for i in tqdm(range(1, num_iters + 1), desc=\"Training with privacy\"):\n",
    "            minibatch_indices = np.random.choice(x.shape[0], minibatch_size, replace=True)\n",
    "            minibatch_x = x[minibatch_indices]\n",
    "            minibatch_y = y[minibatch_indices]\n",
    "            loss = model(minibatch_x, minibatch_y)\n",
    "            loss.backward()\n",
    "            gradient = torch.cat([p.grad.flatten() for p in model.parameters()]).detach().numpy()\n",
    "            pos_alphas = self.compute_alpha_private(constraint, gradient, model, noise_para)\n",
    "            neg_alphas = self.compute_alpha_private(-constraint, gradient, model, noise_para)\n",
    "            alphas = pos_alphas + neg_alphas\n",
    "            min_alpha, size, corner_num = min(alphas, key=lambda x: x[0])\n",
    "            corner = np.zeros(m)\n",
    "            corner[corner_num] = size\n",
    "            mu = 2 / (i + 2)\n",
    "            with torch.no_grad():\n",
    "                index = 0\n",
    "                for p in model.parameters():\n",
    "                    numel = p.numel()\n",
    "                    p_flat = p.view(-1)\n",
    "                    p_flat.copy_((1 - mu) * p_flat + mu * torch.tensor(corner[index:index+numel], dtype=torch.float32))\n",
    "                    index += numel\n",
    "            losses.append(loss.item())\n",
    "            gradients.append(np.linalg.norm(gradient))  # 记录梯度的范数\n",
    "            parameters.append(model.state_dict().copy())\n",
    "            model.zero_grad()\n",
    "\n",
    "        min_loss_index = np.argmin(losses)\n",
    "        model.load_state_dict(parameters[min_loss_index])\n",
    "\n",
    "        # 后处理：将绝对值小于阈值的系数设为0\n",
    "        with torch.no_grad():\n",
    "            model.beta[torch.abs(model.beta) < threshold] = 0\n",
    "\n",
    "        return model, mean, std, losses[-1], self.calculate_mse(model, x, y)\n",
    "\n",
    "    def compute_alpha(self, corner_size, gradient, model):\n",
    "        alpha = gradient * corner_size\n",
    "        corner_size = (np.ones(sum(p.numel() for p in model.parameters())) * corner_size).tolist()\n",
    "        corner_num = np.arange(sum(p.numel() for p in model.parameters())).tolist()\n",
    "        return list(zip(alpha, corner_size, corner_num))\n",
    "\n",
    "    def compute_alpha_private(self, corner_size, gradient, model, noise_para):\n",
    "        alpha = gradient * corner_size\n",
    "        noise = np.random.laplace(scale=noise_para, size=sum(p.numel() for p in model.parameters()))\n",
    "        alpha = alpha + noise\n",
    "        corner_size = (np.ones(sum(p.numel() for p in model.parameters())) * corner_size).tolist()\n",
    "        corner_num = np.arange(sum(p.numel() for p in model.parameters())).tolist()\n",
    "        return list(zip(alpha, corner_size, corner_num))\n",
    "\n",
    "    def calculate_mse(self, model, x, y):\n",
    "        with torch.no_grad():\n",
    "            predictions = model.predict(x)\n",
    "            mse = torch.mean((predictions - y) ** 2).item()\n",
    "        return mse\n",
    "\n",
    "    def calculate_sse(self, beta_hat, beta_true):\n",
    "        return np.sum((beta_hat - beta_true) ** 2)\n",
    "\n",
    "    def calculate_fp(self, beta_hat, beta_true):\n",
    "        return np.sum((beta_true == 0) & (beta_hat != 0))\n",
    "\n",
    "    def calculate_sr(self, beta_hat, beta_true, threshold=1e-3):\n",
    "        return np.linalg.norm(beta_hat - beta_true) <= threshold\n",
    "\n",
    "    def optimize_hyperparameters(self, x, y, method, num_trials=3):\n",
    "        def objective(trial):\n",
    "            # 公共超参数\n",
    "            constraint = trial.suggest_float('constraint', 1, 100)\n",
    "            minibatch_size = trial.suggest_int('minibatch_size', 10, 100)\n",
    "            num_iters = trial.suggest_int('num_iters', 1000, 5000)\n",
    "\n",
    "            if method == 'private':\n",
    "                # 私有方法特有的超参数\n",
    "                lipschitz = trial.suggest_float('lipschitz', 0.1, 1)\n",
    "                model, _, _, loss, mse = self.train_model_private(\n",
    "                    x, y, num_iters=num_iters, constraint=constraint, \n",
    "                    minibatch_size=minibatch_size, lipschitz=lipschitz\n",
    "                )\n",
    "            else:\n",
    "                # 非私有方法不需要 lipschitz 参数\n",
    "                model, _, _, loss, mse = self.train_model_without_private(\n",
    "                    x, y, num_iters=num_iters, constraint=constraint, \n",
    "                    minibatch_size=minibatch_size\n",
    "                )\n",
    "            return loss\n",
    "\n",
    "        study = optuna.create_study(direction='minimize')\n",
    "        study.optimize(objective, n_trials=num_trials)\n",
    "        return study.best_params\n",
    "\n",
    "    def run_experiments(self, N_values, epsilon_values, num_repeats=100):\n",
    "        results = []\n",
    "        for N in N_values:\n",
    "            # 生成数据，并保存真实参数\n",
    "            true_params_path = f'true_parameters_N{N}.csv'\n",
    "            x, y, true_beta = self.generate_data(N, save_path=true_params_path)\n",
    "\n",
    "            # 划分训练集和测试集\n",
    "            x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)\n",
    "            pd.DataFrame(np.hstack([x, y.reshape(-1, 1)]), columns=[f'x{i}' for i in range(self.num_features)] + ['y']).to_csv(f'data_{N}.csv', index=False)\n",
    "\n",
    "            for epsilon in epsilon_values:\n",
    "                for method in ['mle', 'without_private', 'private']:\n",
    "                    if method == 'mle':\n",
    "                        # MLE 方法使用自适应 Lasso 进行变量选择\n",
    "                        beta, lambda_, sigma_sq, mse, bic, best_r = self.stochastic_frontier_mle_lasso_bic(x_train, y_train)\n",
    "                        # 计算 SSE, FP, SR\n",
    "                        sse = self.calculate_sse(beta, true_beta)\n",
    "                        fp = self.calculate_fp(beta, true_beta)\n",
    "                        sr = self.calculate_sr(beta, true_beta)\n",
    "                        hyperparams = {'best_r': best_r}\n",
    "                    else:\n",
    "                        # 使用交叉验证优化超参数\n",
    "                        hyperparams = self.optimize_hyperparameters(x_train, y_train, method)\n",
    "                        beta_list, lambda_list, sigma_sq_list, mse_list, loss_list = [], [], [], [], []\n",
    "                        sse_list, fp_list, sr_list = [], [], []\n",
    "                        for _ in range(num_repeats):\n",
    "                            if method == 'private':\n",
    "                                model, _, _, loss, mse = self.train_model_private(x_train, y_train, **hyperparams, epsilon=epsilon)\n",
    "                            else:\n",
    "                                model, _, _, loss, mse = self.train_model_without_private(x_train, y_train, **hyperparams)\n",
    "                            beta_hat = model.beta.detach().numpy()\n",
    "                            beta_list.append(beta_hat)\n",
    "                            lambda_list.append(torch.exp(model.log_lambda0).item())\n",
    "                            sigma_sq_list.append(torch.exp(model.log_sigma2).item())\n",
    "                            # 在测试集上计算 MSE\n",
    "                            with torch.no_grad():\n",
    "                                y_pred = model.predict(torch.tensor(x_test, dtype=torch.float32)).numpy()\n",
    "                                test_mse = np.mean((y_test - y_pred) ** 2)\n",
    "                            mse_list.append(test_mse)\n",
    "                            loss_list.append(loss)\n",
    "                            # 计算 SSE, FP, SR\n",
    "                            sse_list.append(self.calculate_sse(beta_hat, true_beta))\n",
    "                            fp_list.append(self.calculate_fp(beta_hat, true_beta))\n",
    "                            sr_list.append(self.calculate_sr(beta_hat, true_beta))\n",
    "                        # 计算平均值\n",
    "                        beta = np.mean(beta_list, axis=0)\n",
    "                        lambda_ = np.mean(lambda_list)\n",
    "                        sigma_sq = np.mean(sigma_sq_list)\n",
    "                        mse = np.mean(mse_list)\n",
    "                        loss = np.mean(loss_list)\n",
    "                        sse = np.mean(sse_list)\n",
    "                        fp = np.mean(fp_list)\n",
    "                        sr = np.mean(sr_list)\n",
    "    \n",
    "                    # 保存结果\n",
    "                    results.append({\n",
    "                        'N': N,\n",
    "                        'epsilon': epsilon,\n",
    "                        'method': method,\n",
    "                        'beta': beta,\n",
    "                        'lambda': lambda_,\n",
    "                        'sigma_sq': sigma_sq,\n",
    "                        'mse': mse,\n",
    "                        'loss': loss,\n",
    "                        'sse': sse,\n",
    "                        'fp': fp,\n",
    "                        'sr': sr,\n",
    "                        'hyperparams': hyperparams\n",
    "                    })\n",
    "        # 保存结果到 CSV\n",
    "        pd.DataFrame(results).to_csv('result.csv', index=False)\n",
    "\n",
    "# 可视化函数\n",
    "def plot_beta_comparison(result_path, true_params_path, threshold=1e-3):\n",
    "    \"\"\"\n",
    "    可视化真实值与估计值的对比图，高亮被选择的变量。\n",
    "    :param result_path: 包含估计结果的 CSV 文件路径\n",
    "    :param true_params_path: 包含真实参数的 CSV 文件路径\n",
    "    :param threshold: 变量选择的阈值\n",
    "    \"\"\"\n",
    "    # 读取估计结果和真实参数\n",
    "    result_df = pd.read_csv(result_path)\n",
    "    true_params_df = pd.read_csv(true_params_path)\n",
    "\n",
    "    # 提取真实 beta 和估计 beta\n",
    "    true_beta = true_params_df['beta'].values\n",
    "    estimated_beta = result_df['beta'].values\n",
    "\n",
    "    # 确保 beta 的维度一致\n",
    "    if len(true_beta) != len(estimated_beta):\n",
    "        raise ValueError(\"真实 beta 和估计 beta 的维度不一致！\")\n",
    "\n",
    "    # 创建 DataFrame 用于绘图\n",
    "    beta_df = pd.DataFrame({\n",
    "        'Dimension': np.arange(len(true_beta)),  # 横轴：维度\n",
    "        'True Beta': true_beta,  # 纵轴：真实值\n",
    "        'Estimated Beta': estimated_beta,  # 纵轴：估计值\n",
    "        'Selected': (np.abs(true_beta) > threshold)  # 高亮被选择的变量\n",
    "    })\n",
    "\n",
    "    # 设置 Seaborn 风格\n",
    "    sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # 绘制真实值和估计值的散点图\n",
    "    sns.scatterplot(x='Dimension', y='True Beta', data=beta_df, color='blue', label='True Beta', s=100, alpha=0.7)\n",
    "    sns.scatterplot(x='Dimension', y='Estimated Beta', data=beta_df, color='red', label='Estimated Beta', s=100, alpha=0.7)\n",
    "\n",
    "    # 绘制差异线\n",
    "    for i in range(len(beta_df)):\n",
    "        plt.plot([beta_df['Dimension'][i], beta_df['Dimension'][i]],\n",
    "                 [beta_df['True Beta'][i], beta_df['Estimated Beta'][i]],\n",
    "                 color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # 高亮被选择的变量\n",
    "    selected_points = beta_df[beta_df['Selected']]\n",
    "    sns.scatterplot(x='Dimension', y='True Beta', data=selected_points, color='green', label='Selected Variables', s=150, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "    # 添加标题和标签\n",
    "    plt.title('Comparison of True Beta and Estimated Beta with Variable Selection', fontsize=16)\n",
    "    plt.xlabel('Dimension', fontsize=14)\n",
    "    plt.ylabel('Beta Value', fontsize=14)\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 示例调用\n",
    "num_features = 500  # 特征维度为 500\n",
    "sigma_u = 0.3  # 非负噪声的标准差\n",
    "sigma_v = 0.5  # 随机噪声的标准差\n",
    "sfa = StochasticFrontierAnalysis(num_features, sigma_u, sigma_v)\n",
    "sfa.run_experiments(N_values=[5000], epsilon_values=[1])\n",
    "\n",
    "# 可视化结果\n",
    "result_path = 'result.csv'  # 包含估计结果的 CSV 文件路径\n",
    "true_params_path = 'true_parameters_N5000.csv'  # 包含真实参数的 CSV 文件路径\n",
    "plot_beta_comparison(result_path, true_params_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1a1363",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_beta_comparison(csv_path, true_beta_path, threshold=1e-3):\n",
    "    \"\"\"\n",
    "    可视化真实值与估计值的对比图，高亮被选择的变量。\n",
    "    :param csv_path: 包含估计 beta 的 CSV 文件路径\n",
    "    :param true_beta_path: 包含真实 beta 的 CSV 文件路径\n",
    "    :param threshold: 变量选择的阈值\n",
    "    \"\"\"\n",
    "    # 读取估计的 beta 和真实的 beta\n",
    "    df = pd.read_csv(csv_path)\n",
    "    true_beta = pd.read_csv(true_beta_path).values.flatten()  # 真实 beta\n",
    "    estimated_beta = df['beta'].values  # 估计的 beta\n",
    "\n",
    "    # 确保 beta 的维度一致\n",
    "    if len(true_beta) != len(estimated_beta):\n",
    "        raise ValueError(\"真实 beta 和估计 beta 的维度不一致！\")\n",
    "\n",
    "    # 创建 DataFrame 用于绘图\n",
    "    beta_df = pd.DataFrame({\n",
    "        'Dimension': np.arange(len(true_beta)),  # 横轴：维度\n",
    "        'True Beta': true_beta,  # 纵轴：真实值\n",
    "        'Estimated Beta': estimated_beta,  # 纵轴：估计值\n",
    "        'Selected': (np.abs(true_beta) > threshold)  # 高亮被选择的变量\n",
    "    })\n",
    "\n",
    "    # 设置 Seaborn 风格\n",
    "    sns.set(style=\"whitegrid\", font_scale=1.2)\n",
    "    plt.figure(figsize=(12, 6))\n",
    "\n",
    "    # 绘制真实值和估计值的散点图\n",
    "    sns.scatterplot(x='Dimension', y='True Beta', data=beta_df, color='blue', label='True Beta', s=100, alpha=0.7)\n",
    "    sns.scatterplot(x='Dimension', y='Estimated Beta', data=beta_df, color='red', label='Estimated Beta', s=100, alpha=0.7)\n",
    "\n",
    "    # 绘制差异线\n",
    "    for i in range(len(beta_df)):\n",
    "        plt.plot([beta_df['Dimension'][i], beta_df['Dimension'][i]],\n",
    "                 [beta_df['True Beta'][i], beta_df['Estimated Beta'][i]],\n",
    "                 color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "    # 高亮被选择的变量\n",
    "    selected_points = beta_df[beta_df['Selected']]\n",
    "    sns.scatterplot(x='Dimension', y='True Beta', data=selected_points, color='green', label='Selected Variables', s=150, edgecolor='black', linewidth=1.5)\n",
    "\n",
    "    # 添加标题和标签\n",
    "    plt.title('Comparison of True Beta and Estimated Beta with Variable Selection', fontsize=16)\n",
    "    plt.xlabel('Dimension', fontsize=14)\n",
    "    plt.ylabel('Beta Value', fontsize=14)\n",
    "    plt.legend(loc='upper right', fontsize=12)\n",
    "\n",
    "    # 调整布局\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# 示例调用\n",
    "csv_path = 'result.csv'  # 包含估计 beta 的 CSV 文件路径\n",
    "true_beta_path = 'true_beta.csv'  # 包含真实 beta 的 CSV 文件路径\n",
    "plot_beta_comparison(csv_path, true_beta_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3e24a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# import scienceplots\n",
    "\n",
    "# # 设置 scienceplots 样式\n",
    "# plt.style.use(['science', 'ieee'])\n",
    "\n",
    "# # 创建数据\n",
    "# np.random.seed(0)\n",
    "# dimensions = np.arange(1, 501)\n",
    "# true_coefficient = np.zeros(500)\n",
    "# estimated_values = np.random.normal(0, 0.2, 500)\n",
    "\n",
    "# # 添加几个异常值以匹配图中的情况\n",
    "# true_coefficient[[200, 300, 400, 499]] = [1, -1, 1, -1]\n",
    "# estimated_values[[100, 200, 300, 400, 499]] = [1, 1, -1, 1, -1]\n",
    "\n",
    "# # 计算差异\n",
    "# difference = estimated_values - true_coefficient\n",
    "\n",
    "# # 绘制图形\n",
    "# plt.figure(figsize=(12, 6))\n",
    "\n",
    "# # 绘制真实系数\n",
    "# plt.scatter(dimensions, true_coefficient, marker='D', color='blue', label='True coefficient (beta)', alpha=0.8)\n",
    "\n",
    "# # 绘制估计值\n",
    "# plt.scatter(dimensions, estimated_values, marker='s', color='red', label='Estimated values (A-Trans-QMR)', alpha=0.8)\n",
    "\n",
    "# # 高亮被选择的变量（真实值不为零的点）\n",
    "# selected_indices = np.where(true_coefficient != 0)[0]\n",
    "# plt.scatter(dimensions[selected_indices], true_coefficient[selected_indices], \n",
    "#             marker='D', color='green', s=100, label='Selected variables', edgecolor='black', linewidth=1.5)\n",
    "\n",
    "# # 添加差异线\n",
    "# for i in range(len(dimensions)):\n",
    "#     plt.plot([dimensions[i], dimensions[i]], [true_coefficient[i], estimated_values[i]], \n",
    "#              color='gray', linestyle='--', alpha=0.5)\n",
    "\n",
    "# # 添加标题和标签\n",
    "# plt.title('Comparison of True Coefficients and Estimated Values (K=5)', fontsize=16)\n",
    "# plt.xlabel('Dimension', fontsize=14)\n",
    "# plt.ylabel('Value', fontsize=14)\n",
    "\n",
    "# # 添加图例\n",
    "# plt.legend(fontsize=12, loc='upper right')\n",
    "\n",
    "# # 显示图形\n",
    "# plt.tight_layout()\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc9aaf83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27ca121c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
